all.icp <- main.icp %>%
left_join(df.icp.f, by = 'sample_name')
if(exists("df.icp.all")) {
df.icp.all <- all.icp
}
for(var in names(df.f)) {
print(paste('merging: ', var))
var.x = paste0(var,".x")
var.y = paste0(var,".y")
if(var.x %in% names(all.icp)) {
if(!exists("df.icp.all")) {
icp.i <- all.icp
} else {
icp.i <- df.icp.all
}
var__flag = paste0(var, "__flag")
df.icp.all <- icp.i %>%
mutate(
!!var := ifelse(is.na(.data[[var.x]]), .data[[var.y]], .data[[var.x]]),
!!var__flag := ifelse(grepl(" L", .data[[var]]), "BDL", NA),
!!var__flag := ifelse(grepl(" H", .data[[var]]), "ADL", NA),
!!var := gsub(" L", "", .data[[var]]),
!!var := gsub(" H", "", .data[[var]]),
!!var := as.numeric(.data[[var]], na.pass = TRUE),
) %>%
select(-.data[[var.x]], -.data[[var.y]])
} else {
print(paste("Skipping", var))
}
}
head(df.icp.all)
usethis::use_vignette(name = 'longitudinal_wqm_nhd', 'longitudinal water quality data analysis')
library(bayTools)
devtools::build()
.Last.error
devtools::build()
usethis::use_pipe()
use_testthat()
usethis::use_testthat()
use_r('bt_get_site_data')
usethis::use_r('bt_get_site_data')
usethis::use_test('bt_get_site_data')
install.packages('roxygen2')
use_package("dplyr")
usethis::use_package("dplyr")
devtools::build()
devtools::load_all()
devtools::build()
devtools::load_all()
devtools::build()
devtools::load_all()
library(bayTools)
install()
devtools::check(())
devtools::check()
devtools::check()
library(usethis)
library(devtools)
library(roxygen2)
use_roxygen_md()
install()
check()
use_r('bt_get_site_data')
document()
document()
use_r('bt_get_site_data')
document()
devtools::build()
devtools::load_all()
document()
library(bayTools)
site_data <- bt_get_site_data()
use_r("bt_get_wqm_data")
use_test("bt_get_wqm_data")
bt_get_wqm_data <- function(
wq.field.ss = "https://docs.google.com/spreadsheets/d/1ASyFVJU3UBVRAC9Ys-Vz8PuVIsJWiFMuJJab42NgEbQ/edit#gid=1906575016",
wq.sites.ss = "https://docs.google.com/spreadsheets/d/-1Ez07N7a6Qh-vAWBu1CVS1S2UuI_58gcKvwrZDDKMsbI/edit#gid=0",
wq.lab.ss = "https://docs.google.com/spreadsheets/d/17CMguyAioEv3_qEkUUXe67UbBmJ6ACnNxCKu3W2kmx0/edit#gid=0"
) {
wq.field <- read_sheet(ss = wq.field.ss)
wq.sites <- read_sheet(ss = wq.sites.ss,
sheet = "site_data_ext")
# summarize wq field data to get relevant info (start/end date)
wq.field.stat <- wq.field %>%
group_by(Site) %>%
summarise(
start_date = min(Date) - 7,
end_date = max(Date)
) %>%
rename(
site_code = Site
)
wq.weather <- wq.sites %>%
select(site_code, lat, long) %>%
left_join(wq.field.stat, by = "site_code")
wq.weather.run <- wq.weather %>%
filter(!is.na(start_date)) %>%
mutate(
start_date = as.Date(start_date),
end_date = as.Date(end_date)
)
# cleaning
wq.field.weather <- wq.field %>%
rename(
site_code = Site,
date = Date
)
# rm(wq.weather.data)
# retrieve weather
for(i in 1:nrow(wq.weather.run)) {
site_row    =  wq.weather.run[i,]
site        =  site_row$site_code
site_coords =  c(site_row$lat, site_row$long)
site_start  =  site_row$start_date - 7 # one week before start
site_end    =  site_row$end_date + 1 # one day after
print(paste('querying openmeteo weather data for site:', site))
site.weather <- openmeteo::weather_history(
location = site_coords,
start = site_start,
end = site_end,
daily = c('temperature_2m_mean',
'precipitation_sum',
'rain_sum',
'snowfall_sum',
'windspeed_10m_mean',
'shortwave_radiation_sum'
)
) %>%
mutate(
site_code = site,
precip_3day_sum = zoo::rollsum(daily_precipitation_sum, 3, fill = NA),
rain_3day_sum = zoo::rollsum(daily_rain_sum, 3, fill = NA),
snow_3day_sum = zoo::rollsum(daily_snowfall_sum, 3, fill = NA),
temp_2day_mean = zoo::rollmean(daily_temperature_2m_mean, 3, fill = NA)
)
site.field.weather.row = left_join(wq.field.weather, site.weather, by = c('site_code', 'date')) %>%
filter(site_code == site)
if(!exists("wq.weather.data")) {
wq.weather.data <- site.field.weather.row
} else {
wq.weather.data <- rbind(wq.weather.data, site.field.weather.row)
}
}
# rm(wq.weather.data)
# write_sheet(wq.weather.data,
#             ss = "https://docs.google.com/spreadsheets/d/1BB2YELUcibd1c8N9EfHr3OGz1gAhNZwy-O6I2wAAkNc/edit#gid=0",
#             sheet = "wq_weather")
# merge with lab data
wq.lab <- read_sheet(ss = "https://docs.google.com/spreadsheets/d/17CMguyAioEv3_qEkUUXe67UbBmJ6ACnNxCKu3W2kmx0/edit#gid=0")
wq.lab.f <- wq.lab %>%
mutate(
date = as.Date(Date, format = "%y%m%d"),
site_code = Site
)
wq.all <- left_join(wq.weather.data, wq.lab.f, by = c("site_code", "date"))
write_sheet(wq.all,
ss = "https://docs.google.com/spreadsheets/d/1BB2YELUcibd1c8N9EfHr3OGz1gAhNZwy-O6I2wAAkNc/edit#gid=0",
sheet = "wq_field_lab_weather")
# NOAA Buoy Download
fn = 'noaa_upper_ptomac_2012.zip'
download.file(
url = "http://buoybay.noaa.gov/sites/default/files/data-reports/process-reports.php?station%5B%5D=UP&year%5B%5D=2012&type%5B%5D=ocean&type%5B%5D=met&",
destfile = fn)
unzip(file.path(getwd(), fn))
fp <- file.path(getwd(), 'upper_potomac_conmon', 'UP_OCEAN_2012.csv')
upper_potomac__NOAA_2012 <- read.csv(fp)
# NHD data retrieval
library(nhdplusTools)
sites.sf <- sf::st_as_sf(wq.sites, coords = c("long", "lat"), crs = 4326)
# look up NHD reach ID for every latlong
nhd_ids <- c()
for(i in 1:nrow(sites.sf)) {
site_nhd_id <- nhdplusTools::discover_nhdplus_id(sites.sf[i,])
nhd_ids <- append(nhd_ids, site_nhd_id)
}
wq.sites$nhd_comid <- nhd_ids
sites.nhd.info <-  get_nhdplus(sites.sf[1,])
for(i in 2:nrow(sites.sf)) {
sites.nhd.info <- rbind(sites.nhd.info, get_nhdplus(sites.sf[i,]))
}
sites.nhd.info$site_code <- sites.sf$site_code
write_sheet(sf::st_drop_geometry(sites.nhd.info),
ss = "https://docs.google.com/spreadsheets/d/1Ez07N7a6Qh-vAWBu1CVS1S2UuI_58gcKvwrZDDKMsbI/edit#gid=0",
sheet = "nhd")
wq.sites.nhd <- sf::st_drop_geometry(sites.nhd.info) %>%
select(-site_code)
wq.sites.ext <- cbind(wq.sites, wq.sites.nhd)
write_sheet(wq.sites.ext,
ss = "https://docs.google.com/spreadsheets/d/1Ez07N7a6Qh-vAWBu1CVS1S2UuI_58gcKvwrZDDKMsbI/edit#gid=0",
sheet = "site_data_ext")
### NHD boneyard
pr_mouth_comid <- wq.sites[wq.sites$site_code == "PR-mouth",]$nhd_comid
site_nhd_BFI <- nhdplusTools::get_catchment_characteristics("CAT_BFI",
nhd_ids)
dest_comid <- rep(pr_mouth_comid, nrow(wq.sites))
ID = nhd_ids
toID = dest_comid
length = sites.nhd.info$lengthkm
site.df <- data.frame(ID, toID, length) %>%
filter(ID != dest_comid)
site_nhd_path_lengths <- nhdplusTools::get_pathlength(site.df)
for(i in 1:nrow(wq.sites)) {
site_comid <- wq.sites$nhd_comid[i]
site_nhd_chars <- nhdplusTools::get_catchment_characteristics("CAT_BFI",
site_comid)
path_lengths <- nhdplusTools::get_pathlength(site_comid)
}
pr_mouth_comid <- wq.sites[wq.sites$site_code == "PR-mouth",]$nhd_comid
site_nhd_BFI <- nhdplusTools::get_catchment_characteristics("CAT_BFI",
nhd_ids)
dest_comid <- rep(pr_mouth_comid, nrow(wq.sites))
ID = nhd_ids
toID = dest_comid
length = rep("", nrow(wq.sites))
site.df <- data.frame(ID, toID, length) %>%
filter(ID != dest_comid)
site_nhd_path_lengths <- nhdplusTools::get_pathlength(site.df)
}
wq.field.ss = "https://docs.google.com/spreadsheets/d/1ASyFVJU3UBVRAC9Ys-Vz8PuVIsJWiFMuJJab42NgEbQ/edit#gid=1906575016",
wq.lab.ss = "https://docs.google.com/spreadsheets/d/17CMguyAioEv3_qEkUUXe67UbBmJ6ACnNxCKu3W2kmx0/edit#gid=0"
wq.sites.ss = "https://docs.google.com/spreadsheets/d/-1Ez07N7a6Qh-vAWBu1CVS1S2UuI_58gcKvwrZDDKMsbI/edit#gid=0"
wq.field.ss = "https://docs.google.com/spreadsheets/d/1ASyFVJU3UBVRAC9Ys-Vz8PuVIsJWiFMuJJab42NgEbQ/edit#gid=1906575016"
wq.field <- read_sheet(ss = wq.field.ss)
wq.field <- googlesheets4::read_sheet(ss = wq.field.ss)
wq.sites <- googlesheets4::read_sheet(ss = wq.sites.ss,
sheet = "site_data_ext")
wq.sites.ss = "https://docs.google.com/spreadsheets/d/1Ez07N7a6Qh-vAWBu1CVS1S2UuI_58gcKvwrZDDKMsbI/edit#gid=0"
wq.sites <- googlesheets4::read_sheet(ss = wq.sites.ss,
sheet = "site_data_ext")
# summarize wq field data to get relevant info (start/end date)
wq.field.stat <- wq.field %>%
group_by(Site) %>%
summarise(
start_date = min(Date) - 7,
end_date = max(Date)
) %>%
rename(
site_code = Site
)
wq.weather <- wq.sites %>%
select(site_code, lat, long) %>%
left_join(wq.field.stat, by = "site_code")
wq.weather.run <- wq.weather %>%
filter(!is.na(start_date)) %>%
mutate(
start_date = as.Date(start_date),
end_date = as.Date(end_date)
)
# cleaning
wq.field.weather <- wq.field %>%
rename(
site_code = Site,
date = Date
)
# rm(wq.weather.data)
# retrieve weather
for(i in 1:nrow(wq.weather.run)) {
site_row    =  wq.weather.run[i,]
site        =  site_row$site_code
site_coords =  c(site_row$lat, site_row$long)
site_start  =  site_row$start_date - 7 # one week before start
site_end    =  site_row$end_date + 1 # one day after
print(paste('querying openmeteo weather data for site:', site))
site.weather <- openmeteo::weather_history(
location = site_coords,
start = site_start,
end = site_end,
daily = c('temperature_2m_mean',
'precipitation_sum',
'rain_sum',
'snowfall_sum',
'windspeed_10m_mean',
'shortwave_radiation_sum'
)
) %>%
mutate(
site_code = site,
precip_3day_sum = zoo::rollsum(daily_precipitation_sum, 3, fill = NA),
rain_3day_sum = zoo::rollsum(daily_rain_sum, 3, fill = NA),
snow_3day_sum = zoo::rollsum(daily_snowfall_sum, 3, fill = NA),
temp_2day_mean = zoo::rollmean(daily_temperature_2m_mean, 3, fill = NA)
)
site.field.weather.row = left_join(wq.field.weather, site.weather, by = c('site_code', 'date')) %>%
filter(site_code == site)
if(!exists("wq.weather.data")) {
wq.weather.data <- site.field.weather.row
} else {
wq.weather.data <- rbind(wq.weather.data, site.field.weather.row)
}
}
rm(wq.weather.data)
# retrieve weather
for(i in 1:nrow(wq.weather.run)) {
site_row    =  wq.weather.run[i,]
site        =  site_row$site_code
site_coords =  c(site_row$lat, site_row$long)
site_start  =  site_row$start_date - 7 # one week before start
site_end    =  site_row$end_date #
print(paste('querying openmeteo weather data for site:', site))
site.weather <- openmeteo::weather_history(
location = site_coords,
start = site_start,
end = site_end,
daily = c('temperature_2m_mean',
'precipitation_sum',
'rain_sum',
'snowfall_sum',
'windspeed_10m_mean',
'shortwave_radiation_sum'
)
) %>%
mutate(
site_code = site,
precip_3day_sum = zoo::rollsum(daily_precipitation_sum, 3, fill = NA),
rain_3day_sum = zoo::rollsum(daily_rain_sum, 3, fill = NA),
snow_3day_sum = zoo::rollsum(daily_snowfall_sum, 3, fill = NA),
temp_2day_mean = zoo::rollmean(daily_temperature_2m_mean, 3, fill = NA)
)
site.field.weather.row = left_join(wq.field.weather, site.weather, by = c('site_code', 'date')) %>%
filter(site_code == site)
if(!exists("wq.weather.data")) {
wq.weather.data <- site.field.weather.row
} else {
wq.weather.data <- rbind(wq.weather.data, site.field.weather.row)
}
}
# summarize wq field data to get relevant info (start/end date)
wq.field.stat <- wq.field %>%
group_by(Site) %>%
summarise(
start_date = min(Date),
end_date = max(Date)
) %>%
rename(
site_code = Site
)
wq.weather <- wq.sites %>%
select(site_code, lat, long) %>%
left_join(wq.field.stat, by = "site_code")
wq.weather.run <- wq.weather %>%
filter(!is.na(start_date)) %>%
mutate(
start_date = as.Date(start_date),
end_date = as.Date(end_date)
)
# cleaning
wq.field.weather <- wq.field %>%
rename(
site_code = Site,
date = Date
)
rm(wq.weather.data)
# retrieve weather
for(i in 1:nrow(wq.weather.run)) {
site_row    =  wq.weather.run[i,]
site        =  site_row$site_code
site_coords =  c(site_row$lat, site_row$long)
site_start  =  site_row$start_date - 7 # one week before start
site_end    =  site_row$end_date - 1 # one day before end (in case end is today)
print(paste('querying openmeteo weather data for site:', site))
site.weather <- openmeteo::weather_history(
location = site_coords,
start = site_start,
end = site_end,
daily = c('temperature_2m_mean',
'precipitation_sum',
'rain_sum',
'snowfall_sum',
'windspeed_10m_mean',
'shortwave_radiation_sum'
)
) %>%
mutate(
site_code = site,
precip_3day_sum = zoo::rollsum(daily_precipitation_sum, 3, fill = NA),
rain_3day_sum = zoo::rollsum(daily_rain_sum, 3, fill = NA),
snow_3day_sum = zoo::rollsum(daily_snowfall_sum, 3, fill = NA),
temp_2day_mean = zoo::rollmean(daily_temperature_2m_mean, 3, fill = NA)
)
site.field.weather.row = left_join(wq.field.weather, site.weather, by = c('site_code', 'date')) %>%
filter(site_code == site)
if(!exists("wq.weather.data")) {
wq.weather.data <- site.field.weather.row
} else {
wq.weather.data <- rbind(wq.weather.data, site.field.weather.row)
}
}
Sys.Date()
# summarize wq field data to get relevant info (start/end date)
wq.field.stat <- wq.field %>%
group_by(Site) %>%
summarise(
start_date = min(Date),
end_date = max(Date)
) %>%
rename(
site_code = Site
) %>%
filter(
start_date > as.Date("1940-01-01"),
end_date < Sys.Date(),
)
# summarize wq field data to get relevant info (start/end date)
wq.field.stat <- wq.field %>%
group_by(Site) %>%
summarise(
start_date = min(Date),
end_date = max(Date)
) %>%
rename(
site_code = Site
) %>%
filter(
start_date > "1940-01-01",
end_date < Sys.Date(),
)
# summarize wq field data to get relevant info (start/end date)
wq.field.stat <- wq.field %>%
group_by(Site) %>%
summarise(
start_date = min(Date),
end_date = max(Date)
) %>%
rename(
site_code = Site
) %>%
filter(
start_date > "1940-01-01",
end_date < as.character(Sys.Date()),
)
wq.weather <- wq.sites %>%
select(site_code, lat, long) %>%
left_join(wq.field.stat, by = "site_code")
wq.weather.run <- wq.weather %>%
filter(!is.na(start_date)) %>%
mutate(
start_date = as.Date(start_date),
end_date = as.Date(end_date)
)
# cleaning
wq.field.weather <- wq.field %>%
rename(
site_code = Site,
date = Date
)
rm(wq.weather.data)
# retrieve weather
for(i in 1:nrow(wq.weather.run)) {
site_row    =  wq.weather.run[i,]
site        =  site_row$site_code
site_coords =  c(site_row$lat, site_row$long)
site_start  =  site_row$start_date - 7 # one week before start
site_end    =  site_row$end_date - 1 # one day before end (in case end is today)
print(paste('querying openmeteo weather data for site:', site))
site.weather <- openmeteo::weather_history(
location = site_coords,
start = site_start,
end = site_end,
daily = c('temperature_2m_mean',
'precipitation_sum',
'rain_sum',
'snowfall_sum',
'windspeed_10m_mean',
'shortwave_radiation_sum'
)
) %>%
mutate(
site_code = site,
precip_3day_sum = zoo::rollsum(daily_precipitation_sum, 3, fill = NA),
rain_3day_sum = zoo::rollsum(daily_rain_sum, 3, fill = NA),
snow_3day_sum = zoo::rollsum(daily_snowfall_sum, 3, fill = NA),
temp_2day_mean = zoo::rollmean(daily_temperature_2m_mean, 3, fill = NA)
)
site.field.weather.row = left_join(wq.field.weather, site.weather, by = c('site_code', 'date')) %>%
filter(site_code == site)
if(!exists("wq.weather.data")) {
wq.weather.data <- site.field.weather.row
} else {
wq.weather.data <- rbind(wq.weather.data, site.field.weather.row)
}
}
# merge with lab data
wq.lab <- googlesheets4::read_sheet(ss = wq.lab.ss)
wq.lab.f <- wq.lab %>%
mutate(
date = as.Date(Date, format = "%y%m%d"),
site_code = Site
)
wq.all <- left_join(wq.weather.data, wq.lab.f, by = c("site_code", "date"))
nrow(wq.weather.data)
wq.weather.data <- wq.weather.data %>%
distinct()
nrow(wq.weather.data)
nrow(wq.lab.f)
wq.lab.f <- wq.lab.f %>%
distinct()
nrow(wq.lab.f)
wq.all <- left_join(wq.weather.data, wq.lab.f, by = c("site_code", "date"))
write_sheet(wq.all,
ss = "https://docs.google.com/spreadsheets/d/1BB2YELUcibd1c8N9EfHr3OGz1gAhNZwy-O6I2wAAkNc/edit#gid=0",
sheet = "wq_field_lab_weather")
googlesheets4::write_sheet(wq.all,
ss = "https://docs.google.com/spreadsheets/d/1BB2YELUcibd1c8N9EfHr3OGz1gAhNZwy-O6I2wAAkNc/edit#gid=0",
sheet = "wq_field_lab_weather")
use_package('openmeteo')
use_package('googlesheets4')
devtools::build()
devtools::install()
check()
document()
document()
devtools::load_all()
